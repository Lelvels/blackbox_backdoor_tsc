{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b949fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4abfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Preprocess the data by applying z-normalization and reshaping if necessary.\n",
    "    \n",
    "    Args:\n",
    "        x_train: Training data\n",
    "        x_test: Test data\n",
    "        univariate: Whether the data is univariate (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing preprocessed x_train and x_test\n",
    "    \"\"\"\n",
    "    # Transform the labels from integers to one hot vectors\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "    if len(x_train.shape) == 2:  # if univariate\n",
    "        # add a dimension to make it multivariate with one dimension \n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504cfcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (3149291, 120, 5), (3149291,), (787323, 120, 5), (787323,)\n",
      "Shape of total dataset: (3936614, 120, 5), (3936614,)\n"
     ]
    }
   ],
   "source": [
    "cur_root_dir = \"/home/fmg2/v-thanh/Code/datasets\"\n",
    "archive_name = \"NILMArchive_2025\"\n",
    "dataset_name = \"iAWE\"\n",
    "root_dir_dataset = f\"{cur_root_dir}/{archive_name}/{dataset_name}/train_test_np/\"\n",
    "\n",
    "# Getting the full dataset\n",
    "x_train = np.load(root_dir_dataset + 'X_train_target.npy')\n",
    "y_train = np.load(root_dir_dataset + 'y_train_target.npy')\n",
    "x_test = np.load(root_dir_dataset + 'X_test_target.npy')\n",
    "y_test = np.load(root_dir_dataset + 'y_test_target.npy')\n",
    "print(f\"Shape of dataset: {x_train.shape}, {y_train.shape}, {x_test.shape}, {y_test.shape}\")\n",
    "\n",
    "X_total = np.concatenate((x_train, x_test), axis=0)\n",
    "y_total = np.concatenate((y_train, y_test), axis=0)\n",
    "print(f\"Shape of total dataset: {X_total.shape}, {y_total.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe21ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_x_train, preprocessed_y_train, preprocessed_x_test, preprocessed_y_test, enc = preprocess_data(\n",
    "    x_train, y_train, x_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a725a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total[:, :, [0, 1, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target, x_surro, y_target, y_surro = train_test_split(\n",
    "    X_total, y_total, test_size=0.2, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "print(f\"Shape of the target data: {x_target.shape}, {y_target.shape}\")\n",
    "print(f\"Shape of the surrogate data: {x_surro.shape}, {y_surro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd83b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_target, x_test_target, y_train_target, y_test_target = train_test_split(X_total, y_total, test_size=0.2, random_state=42)\n",
    "print(f\"Shape of the target train data: {x_train_target.shape}, {y_train_target.shape}\")\n",
    "print(f\"Shape of the target test data: {x_test_target.shape}, {y_test_target.shape}\")\n",
    "\n",
    "# Save the target data\n",
    "np.save(root_dir_dataset + 'X_train_target.npy', x_train_target)\n",
    "np.save(root_dir_dataset + 'y_train_target.npy', y_train_target)\n",
    "np.save(root_dir_dataset + 'X_test_target.npy', x_test_target)\n",
    "np.save(root_dir_dataset + 'y_test_target.npy', y_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_surro, x_test_surro, y_train_surro, y_test_surro = train_test_split(x_surro, y_surro, test_size=0.2, random_state=42)\n",
    "print(f\"Shape of the surrogate train data: {x_train_surro.shape}, {y_train_surro.shape}\")\n",
    "print(f\"Shape of the surrogate test data: {x_test_surro.shape}, {y_test_surro.shape}\")\n",
    "\n",
    "# Save the surrogate data\n",
    "np.save(root_dir_dataset + 'X_train_surro.npy', x_train_surro)\n",
    "np.save(root_dir_dataset + 'y_train_surro.npy', y_train_surro)\n",
    "np.save(root_dir_dataset + 'X_test_surro.npy', x_test_surro)\n",
    "np.save(root_dir_dataset + 'y_test_surro.npy', y_test_surro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
